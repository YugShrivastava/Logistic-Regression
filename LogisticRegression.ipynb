{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnHsaXlTESd8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Creation"
      ],
      "metadata": {
        "id": "X60e8vRtYp54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "n = 100\n",
        "\n",
        "x1 = np.random.uniform(-5, 5, n)\n",
        "x2 = np.random.uniform(-5, 5, n)\n",
        "\n",
        "b = -1\n",
        "w1 = 2\n",
        "w2 = 3\n",
        "\n",
        "# Sigmoid Function\n",
        "z = w1 * x1 + w2 * x2 + b\n",
        "p = 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Generate binary labels based on probability\n",
        "y = np.random.binomial(1, p)\n",
        "\n",
        "df = pd.DataFrame({'x1': x1, 'x2': x2, 'y': y})\n",
        "print(df.head())\n",
        "\n",
        "np.save('x1_values.npy', x1)\n",
        "np.save('x2_values.npy', x2)\n",
        "np.save('y_values.npy', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTQW7WUFEWoy",
        "outputId": "d3ce30a4-5fd8-4f1a-c0fa-5538a7ab173f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         x1        x2  y\n",
            "0 -1.254599 -4.685708  0\n",
            "1  4.507143  1.364104  1\n",
            "2  2.319939 -1.856440  0\n",
            "3  0.986585  0.085707  0\n",
            "4 -3.439814  4.075665  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "3skYf_o7Y9kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Initialisation of weights and biases -:\n",
        "np.random.seed(42)\n",
        "w1 = np.random.uniform(-1, 1)\n",
        "w2 = np.random.uniform(-1, 1)\n",
        "b = np.random.uniform(-1, 1)\n",
        "\n",
        "#Loading saved dataset -:\n",
        "x1 = np.load('x1_values.npy')\n",
        "x2 = np.load('x2_values.npy')\n",
        "y = np.load('y_values.npy')\n",
        "\n",
        "# Prediction -:\n",
        "def prediction(w1, x1, w2, x2, b):\n",
        "  z = w1 * x1 + w2 * x2 + b\n",
        "  p = 1 / (1 + np.exp(-z))\n",
        "  return p\n",
        "\n",
        "# Calculating the Cost -: (J -> Cost Function)\n",
        "def costFunction(p, y):\n",
        "    J = np.mean(y * np.log(p) + (1 - y) * np.log(1 - p))\n",
        "    return J\n",
        "\n",
        "# Gradient Descent -:\n",
        "def f(w1, w2, b, x1, x2):\n",
        "  z = w1 * x1 + w2 * x2 + b\n",
        "  return 1.0 / (1.0 + np.exp(-z))\n",
        "\n",
        "def grad_b(w1, w2, b, x1, x2):\n",
        "  fx = f(w1, w2, b, x1, x2)\n",
        "  return np.mean((fx - y) * fx * (1 - fx))\n",
        "\n",
        "def grad_w1(w1, w2, b, x1, x2):\n",
        "  fx = f(w1, w2, b, x1, x2)\n",
        "  return np.mean((fx - y) * fx * (1 - fx) * x1)\n",
        "\n",
        "def grad_w2(w1, w2, b, x1, x2):\n",
        "  fx = f(w1, w2, b, x1, x2)\n",
        "  return np.mean((fx - y) * fx * (1 - fx) * x2)\n",
        "\n",
        "def gradientDescent(p, y, w1, w2, b):\n",
        "    dw1 = grad_w1(w1, w2, b, x1, x2)\n",
        "    dw2 = grad_w2(w1, w2, b, x1, x2)\n",
        "    db = grad_b(w1, w2, b, x1, x2)\n",
        "    return dw1, dw2, db\n",
        "\n",
        "# Model Training -:\n",
        "itr = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "for i in range(itr):\n",
        "  y_predicted = prediction(w1, x1, w2, x2, b)\n",
        "  cost = costFunction(y_predicted, y)\n",
        "\n",
        "  dw1, dw2, db = gradientDescent(p, y, w1, w2, b)\n",
        "\n",
        "  w1 -= learning_rate * dw1\n",
        "  w2 -= learning_rate * dw2\n",
        "  b -= learning_rate * db\n",
        "\n",
        "  if i % 10 == 0:\n",
        "    print(f\"Iteration {i}: Cost = {cost}\")\n",
        "    print(f\"Updated Weights: w1 = {w1}, w2 = {w2}, b = {b}\")\n",
        "    print(\"---------------------------------------------------\")\n",
        "\n",
        "#Testing the accuracy -:\n",
        "y_predicted = prediction(w1, x1, w2, x2, b)\n",
        "y_predicted_binary = np.where(y_predicted >= 0.5, 1, 0)\n",
        "accuracy = np.mean(y_predicted_binary == y)\n",
        "print(f\"Accuracy: {accuracy * 100}%\")\n",
        "\n",
        "np.save('w1_best_fitted.npy', w1)\n",
        "np.save('w2_best_fitted.npy', w2)\n",
        "np.save('b_best_fitted.npy', b)"
      ],
      "metadata": {
        "id": "JCx4UTIuEbs1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac2bdcd9-264f-4d04-c3e9-f00650c90189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Cost = -0.5770330417252929\n",
            "Updated Weights: w1 = -0.24983890945661966, w2 = 0.9016141514826116, b = 0.46388475635178494\n",
            "---------------------------------------------------\n",
            "Iteration 10: Cost = -0.5685249617458038\n",
            "Updated Weights: w1 = -0.23908001682650434, w2 = 0.9034029981857158, b = 0.4628514638908863\n",
            "---------------------------------------------------\n",
            "Iteration 20: Cost = -0.560206327729471\n",
            "Updated Weights: w1 = -0.22841114184868685, w2 = 0.9050733685269687, b = 0.4618141846837245\n",
            "---------------------------------------------------\n",
            "Iteration 30: Cost = -0.5520726026164974\n",
            "Updated Weights: w1 = -0.21783191745146602, w2 = 0.9066288096902476, b = 0.460772495958785\n",
            "---------------------------------------------------\n",
            "Iteration 40: Cost = -0.5441194001434916\n",
            "Updated Weights: w1 = -0.20734193903526466, w2 = 0.9080728270438411, b = 0.45972600970488964\n",
            "---------------------------------------------------\n",
            "Iteration 50: Cost = -0.5363424900320077\n",
            "Updated Weights: w1 = -0.19694078062141115, w2 = 0.9094088832182169, b = 0.4586743729737203\n",
            "---------------------------------------------------\n",
            "Iteration 60: Cost = -0.5287378021050815\n",
            "Updated Weights: w1 = -0.1866280105295578, w2 = 0.9106403972176607, b = 0.45761726771501743\n",
            "---------------------------------------------------\n",
            "Iteration 70: Cost = -0.5213014291437976\n",
            "Updated Weights: w1 = -0.1764032062385259, w2 = 0.9117707436338514, b = 0.4565544101877284\n",
            "---------------------------------------------------\n",
            "Iteration 80: Cost = -0.5140296283621811\n",
            "Updated Weights: w1 = -0.16626596814220929, w2 = 0.9128032520087622, b = 0.455485549991082\n",
            "---------------------------------------------------\n",
            "Iteration 90: Cost = -0.5069188214376809\n",
            "Updated Weights: w1 = -0.1562159319682328, w2 = 0.9137412063754707, b = 0.45441046875971636\n",
            "---------------------------------------------------\n",
            "Iteration 100: Cost = -0.4999655930858014\n",
            "Updated Weights: w1 = -0.14625277968090453, w2 = 0.9145878449890471, b = 0.4533289785666907\n",
            "---------------------------------------------------\n",
            "Iteration 110: Cost = -0.4931666882110423\n",
            "Updated Weights: w1 = -0.13637624874064677, w2 = 0.9153463602459212, b = 0.45224092007755085\n",
            "---------------------------------------------------\n",
            "Iteration 120: Cost = -0.48651900770254924\n",
            "Updated Weights: w1 = -0.12658613963893448, w2 = 0.9160198987790553, b = 0.45114616049770484\n",
            "---------------------------------------------------\n",
            "Iteration 130: Cost = -0.4800196029722585\n",
            "Updated Weights: w1 = -0.11688232167050305, w2 = 0.9166115617078224, b = 0.4500445913542585\n",
            "---------------------------------------------------\n",
            "Iteration 140: Cost = -0.47366566935641663\n",
            "Updated Weights: w1 = -0.10726473694309695, w2 = 0.9171244050155251, b = 0.4489361261522391\n",
            "---------------------------------------------------\n",
            "Iteration 150: Cost = -0.46745453851877694\n",
            "Updated Weights: w1 = -0.09773340265932633, w2 = 0.9175614400237445, b = 0.4478206979438169\n",
            "---------------------------------------------------\n",
            "Iteration 160: Cost = -0.46138367000613806\n",
            "Updated Weights: w1 = -0.08828841173537577, w2 = 0.917925633930923, b = 0.44669825684774545\n",
            "---------------------------------------------------\n",
            "Iteration 170: Cost = -0.45545064211473146\n",
            "Updated Weights: w1 = -0.07892993184747482, w2 = 0.9182199103824455, b = 0.4455687675547662\n",
            "---------------------------------------------------\n",
            "Iteration 180: Cost = -0.4496531422297615\n",
            "Updated Weights: w1 = -0.06965820301931185, w2 = 0.9184471500407319, b = 0.44443220685314094\n",
            "---------------------------------------------------\n",
            "Iteration 190: Cost = -0.4439889568006364\n",
            "Updated Weights: w1 = -0.060473533882048416, w2 = 0.9186101911261563, b = 0.443288561206747\n",
            "---------------------------------------------------\n",
            "Iteration 200: Cost = -0.4384559611114433\n",
            "Updated Weights: w1 = -0.051376296753352826, w2 = 0.9187118299027747, b = 0.4421378244162584\n",
            "---------------------------------------------------\n",
            "Iteration 210: Cost = -0.43305210900040725\n",
            "Updated Weights: w1 = -0.042366921692986656, w2 = 0.9187548210865528, b = 0.4409799953917984\n",
            "---------------------------------------------------\n",
            "Iteration 220: Cost = -0.42777542267374385\n",
            "Updated Weights: w1 = -0.033445889700013595, w2 = 0.9187418781578901, b = 0.43981507606304937\n",
            "---------------------------------------------------\n",
            "Iteration 230: Cost = -0.4226239827488086\n",
            "Updated Weights: w1 = -0.024613725220735672, w2 = 0.9186756735645129, b = 0.43864306945012926\n",
            "---------------------------------------------------\n",
            "Iteration 240: Cost = -0.41759591864908985\n",
            "Updated Weights: w1 = -0.015870988137105545, w2 = 0.9185588388050961, b = 0.43746397791557096\n",
            "---------------------------------------------------\n",
            "Iteration 250: Cost = -0.41268939945972183\n",
            "Updated Weights: w1 = -0.007218265402764091, w2 = 0.9183939643881567, b = 0.4362778016144981\n",
            "---------------------------------------------------\n",
            "Iteration 260: Cost = -0.40790262533717336\n",
            "Updated Weights: w1 = 0.0013438375117884294, w2 = 0.9181835996646966, b = 0.4350845371565895\n",
            "---------------------------------------------------\n",
            "Iteration 270: Cost = -0.40323381955096216\n",
            "Updated Weights: w1 = 0.009814705211802631, w2 = 0.9179302525367126, b = 0.4338841764897306\n",
            "---------------------------------------------------\n",
            "Iteration 280: Cost = -0.3986812212190172\n",
            "Updated Weights: w1 = 0.01819372086647513, w2 = 0.9176363890469218, b = 0.4326767060114087\n",
            "---------------------------------------------------\n",
            "Iteration 290: Cost = -0.39424307878206394\n",
            "Updated Weights: w1 = 0.02648027446351323, w2 = 0.9173044328578772, b = 0.4314621059100144\n",
            "---------------------------------------------------\n",
            "Iteration 300: Cost = -0.38991764424646824\n",
            "Updated Weights: w1 = 0.03467377071551154, w2 = 0.9169367646309974, b = 0.4302403497343367\n",
            "---------------------------------------------------\n",
            "Iteration 310: Cost = -0.38570316820971434\n",
            "Updated Weights: w1 = 0.04277363651946878, w2 = 0.9165357213179356, b = 0.42901140418578004\n",
            "---------------------------------------------------\n",
            "Iteration 320: Cost = -0.3815978956684012\n",
            "Updated Weights: w1 = 0.05077932788742167, w2 = 0.9161035953781367, b = 0.427775229124277\n",
            "---------------------------------------------------\n",
            "Iteration 330: Cost = -0.37760006259558926\n",
            "Updated Weights: w1 = 0.058690336283122285, w2 = 0.9156426339374198, b = 0.4265317777756095\n",
            "---------------------------------------------------\n",
            "Iteration 340: Cost = -0.3737078932627246\n",
            "Updated Weights: w1 = 0.06650619431648891, w2 = 0.9151550379029931, b = 0.4252809971249466\n",
            "---------------------------------------------------\n",
            "Iteration 350: Cost = -0.3699195982713654\n",
            "Updated Weights: w1 = 0.0742264807638089, w2 = 0.9146429610504839, b = 0.42402282847893935\n",
            "---------------------------------------------------\n",
            "Iteration 360: Cost = -0.3662333732516413\n",
            "Updated Weights: w1 = 0.08185082489700161, w2 = 0.9141085090984181, b = 0.42275720817671264\n",
            "---------------------------------------------------\n",
            "Iteration 370: Cost = -0.3626473981777997\n",
            "Updated Weights: w1 = 0.0893789101193571, w2 = 0.9135537387851216, b = 0.4214840684286026\n",
            "---------------------------------------------------\n",
            "Iteration 380: Cost = -0.35915983724635175\n",
            "Updated Weights: w1 = 0.09681047691781118, w2 = 0.912980656962313, b = 0.4202033382605084\n",
            "---------------------------------------------------\n",
            "Iteration 390: Cost = -0.3557688392591246\n",
            "Updated Weights: w1 = 0.1041453251528339, w2 = 0.9123912197187471, b = 0.418914944541265\n",
            "---------------------------------------------------\n",
            "Iteration 400: Cost = -0.3524725384518612\n",
            "Updated Weights: w1 = 0.11138331571628957, w2 = 0.9117873315462036, b = 0.4176188130704646\n",
            "---------------------------------------------------\n",
            "Iteration 410: Cost = -0.3492690557087361\n",
            "Updated Weights: w1 = 0.11852437159514284, w2 = 0.9111708445589359, b = 0.41631486970463705\n",
            "---------------------------------------------------\n",
            "Iteration 420: Cost = -0.34615650010410065\n",
            "Updated Weights: w1 = 0.12556847838465493, w2 = 0.9105435577764406, b = 0.41500304150058975\n",
            "---------------------------------------------------\n",
            "Iteration 430: Cost = -0.34313297071476406\n",
            "Updated Weights: w1 = 0.1325156842988141, w2 = 0.9099072164781139, b = 0.41368325785595145\n",
            "---------------------------------------------------\n",
            "Iteration 440: Cost = -0.3401965586489491\n",
            "Updated Weights: w1 = 0.13936609972828953, w2 = 0.9092635116370709, b = 0.41235545162850323\n",
            "---------------------------------------------------\n",
            "Iteration 450: Cost = -0.3373453492415561\n",
            "Updated Weights: w1 = 0.14611989639733683, w2 = 0.9086140794391105, b = 0.4110195602176522\n",
            "---------------------------------------------------\n",
            "Iteration 460: Cost = -0.33457742436934745\n",
            "Updated Weights: w1 = 0.15277730617098492, w2 = 0.9079605008915895, b = 0.4096755265933393\n",
            "---------------------------------------------------\n",
            "Iteration 470: Cost = -0.3318908648439476\n",
            "Updated Weights: w1 = 0.15933861956268097, w2 = 0.9073043015257702, b = 0.40832330025971814\n",
            "---------------------------------------------------\n",
            "Iteration 480: Cost = -0.3292837528450015\n",
            "Updated Weights: w1 = 0.1658041839905495, w2 = 0.9066469511951134, b = 0.4069628381430345\n",
            "---------------------------------------------------\n",
            "Iteration 490: Cost = -0.3267541743603136\n",
            "Updated Weights: w1 = 0.17217440182771526, w2 = 0.9059898639709514, b = 0.4055941053952237\n",
            "---------------------------------------------------\n",
            "Iteration 500: Cost = -0.32430022160418565\n",
            "Updated Weights: w1 = 0.17844972828892422, w2 = 0.905334398136035, b = 0.40421707610678453\n",
            "---------------------------------------------------\n",
            "Iteration 510: Cost = -0.32191999538940297\n",
            "Updated Weights: w1 = 0.18463066919212875, w2 = 0.9046818562755933, b = 0.40283173392443794\n",
            "---------------------------------------------------\n",
            "Iteration 520: Cost = -0.3196116074323124\n",
            "Updated Weights: w1 = 0.19071777862993514, w2 = 0.9040334854647769, b = 0.40143807257091224\n",
            "---------------------------------------------------\n",
            "Iteration 530: Cost = -0.31737318257414193\n",
            "Updated Weights: w1 = 0.1967116565819562, w2 = 0.9033904775506756, b = 0.40003609626588293\n",
            "---------------------------------------------------\n",
            "Iteration 540: Cost = -0.31520286090510097\n",
            "Updated Weights: w1 = 0.20261294649529044, w2 = 0.9027539695265041, b = 0.39862582004862074\n",
            "---------------------------------------------------\n",
            "Iteration 550: Cost = -0.31309879978085214\n",
            "Updated Weights: w1 = 0.2084223328566336, w2 = 0.9021250439950272, b = 0.39720727000425726\n",
            "---------------------------------------------------\n",
            "Iteration 560: Cost = -0.31105917572365716\n",
            "Updated Weights: w1 = 0.21414053877599917, w2 = 0.9015047297178552, b = 0.39578048339675087\n",
            "---------------------------------------------------\n",
            "Iteration 570: Cost = -0.3090821862028735\n",
            "Updated Weights: w1 = 0.2197683235987232, w2 = 0.9008940022468614, b = 0.3943455087126334\n",
            "---------------------------------------------------\n",
            "Iteration 580: Cost = -0.3071660512915306\n",
            "Updated Weights: w1 = 0.22530648055939642, w2 = 0.9002937846336618, b = 0.3929024056204402\n",
            "---------------------------------------------------\n",
            "Iteration 590: Cost = -0.3053090151974604\n",
            "Updated Weights: w1 = 0.23075583448862055, w2 = 0.8997049482128415, b = 0.3914512448513807\n",
            "---------------------------------------------------\n",
            "Iteration 600: Cost = -0.30350934766892884\n",
            "Updated Weights: w1 = 0.23611723958103817, w2 = 0.8991283134544109, b = 0.3899921080073037\n",
            "---------------------------------------------------\n",
            "Iteration 610: Cost = -0.30176534527592114\n",
            "Updated Weights: w1 = 0.24139157723093568, w2 = 0.8985646508808207, b = 0.38852508730236057\n",
            "---------------------------------------------------\n",
            "Iteration 620: Cost = -0.30007533256922303\n",
            "Updated Weights: w1 = 0.24657975393985726, w2 = 0.8980146820437535, b = 0.38705028524498736\n",
            "---------------------------------------------------\n",
            "Iteration 630: Cost = -0.29843766312022263\n",
            "Updated Weights: w1 = 0.2516826992990836, w2 = 0.8974790805558388, b = 0.38556781426692466\n",
            "---------------------------------------------------\n",
            "Iteration 640: Cost = -0.29685072044496663\n",
            "Updated Weights: w1 = 0.2567013640485017, w2 = 0.8969584731724032, b = 0.38407779630598654\n",
            "---------------------------------------------------\n",
            "Iteration 650: Cost = -0.29531291881646454\n",
            "Updated Weights: w1 = 0.26163671821229917, w2 = 0.896453440918363, b = 0.38258036234918946\n",
            "---------------------------------------------------\n",
            "Iteration 660: Cost = -0.29382270396957044\n",
            "Updated Weights: w1 = 0.2664897493110406, w2 = 0.89596452025539, b = 0.3810756519426783\n",
            "---------------------------------------------------\n",
            "Iteration 670: Cost = -0.2923785537029979\n",
            "Updated Weights: w1 = 0.27126146064899287, w2 = 0.8954922042845397, b = 0.3795638126746441\n",
            "---------------------------------------------------\n",
            "Iteration 680: Cost = -0.2909789783831684\n",
            "Updated Weights: w1 = 0.2759528696750437, w2 = 0.8950369439795973, b = 0.37804499963713617\n",
            "---------------------------------------------------\n",
            "Iteration 690: Cost = -0.28962252135466415\n",
            "Updated Weights: w1 = 0.2805650064151769, w2 = 0.8945991494464995, b = 0.3765193748723359\n",
            "---------------------------------------------------\n",
            "Iteration 700: Cost = -0.2883077592620745\n",
            "Updated Weights: w1 = 0.2850989119742091, w2 = 0.8941791912043037, b = 0.3749871068085\n",
            "---------------------------------------------------\n",
            "Iteration 710: Cost = -0.28703330228799767\n",
            "Updated Weights: w1 = 0.28955563710433185, w2 = 0.8937774014833099, b = 0.37344836969039025\n",
            "---------------------------------------------------\n",
            "Iteration 720: Cost = -0.28579779431190006\n",
            "Updated Weights: w1 = 0.29393624083792735, w2 = 0.8933940755360865, b = 0.371903343008612\n",
            "---------------------------------------------------\n",
            "Iteration 730: Cost = -0.28459991299444976\n",
            "Updated Weights: w1 = 0.29824178918211364, w2 = 0.8930294729573154, b = 0.3703522109318805\n",
            "---------------------------------------------------\n",
            "Iteration 740: Cost = -0.2834383697918396\n",
            "Updated Weights: w1 = 0.302473353872514, w2 = 0.8926838190085383, b = 0.36879516174582927\n",
            "---------------------------------------------------\n",
            "Iteration 750: Cost = -0.2823119099044986\n",
            "Updated Weights: w1 = 0.3066320111838224, w2 = 0.8923573059440797, b = 0.3672323873015785\n",
            "---------------------------------------------------\n",
            "Iteration 760: Cost = -0.28121931216446405\n",
            "Updated Weights: w1 = 0.3107188407948405, w2 = 0.892050094334596, b = 0.3656640824768941\n",
            "---------------------------------------------------\n",
            "Iteration 770: Cost = -0.28015938886556335\n",
            "Updated Weights: w1 = 0.3147349247057821, w2 = 0.8917623143849155, b = 0.36409044465239665\n",
            "---------------------------------------------------\n",
            "Iteration 780: Cost = -0.279130985540415\n",
            "Updated Weights: w1 = 0.3186813462057749, w2 = 0.8914940672430185, b = 0.3625116732049201\n",
            "---------------------------------------------------\n",
            "Iteration 790: Cost = -0.27813298068813014\n",
            "Updated Weights: w1 = 0.3225591888886211, w2 = 0.8912454262972259, b = 0.3609279690197852\n",
            "---------------------------------------------------\n",
            "Iteration 800: Cost = -0.2771642854564591\n",
            "Updated Weights: w1 = 0.3263695357150163, w2 = 0.8910164384588617, b = 0.35933953402343505\n",
            "---------------------------------------------------\n",
            "Iteration 810: Cost = -0.2762238432819968\n",
            "Updated Weights: w1 = 0.33011346811955306, w2 = 0.8908071254278678, b = 0.35774657073758465\n",
            "---------------------------------------------------\n",
            "Iteration 820: Cost = -0.2753106294919264\n",
            "Updated Weights: w1 = 0.3337920651609578, w2 = 0.8906174849390558, b = 0.35614928185576317\n",
            "---------------------------------------------------\n",
            "Iteration 830: Cost = -0.27442365087065407\n",
            "Updated Weights: w1 = 0.3374064027141242, w2 = 0.890447491986884, b = 0.3545478698428775\n",
            "---------------------------------------------------\n",
            "Iteration 840: Cost = -0.27356194519455296\n",
            "Updated Weights: w1 = 0.3409575527026068, w2 = 0.8902971000268497, b = 0.3529425365581976\n",
            "---------------------------------------------------\n",
            "Iteration 850: Cost = -0.27272458073791306\n",
            "Updated Weights: w1 = 0.34444658237032816, w2 = 0.890166242151786, b = 0.35133348290195604\n",
            "---------------------------------------------------\n",
            "Iteration 860: Cost = -0.2719106557530625\n",
            "Updated Weights: w1 = 0.34787455359133534, w2 = 0.8900548322415461, b = 0.3497209084855743\n",
            "---------------------------------------------------\n",
            "Iteration 870: Cost = -0.27111929792750356\n",
            "Updated Weights: w1 = 0.3512425222165072, w2 = 0.8899627660847403, b = 0.3481050113253562\n",
            "---------------------------------------------------\n",
            "Iteration 880: Cost = -0.2703496638207805\n",
            "Updated Weights: w1 = 0.3545515374561744, w2 = 0.889889922471378, b = 0.34648598755935395\n",
            "---------------------------------------------------\n",
            "Iteration 890: Cost = -0.2696009382836763\n",
            "Updated Weights: w1 = 0.35780264129765865, w2 = 0.8898361642554337, b = 0.34486403118697845\n",
            "---------------------------------------------------\n",
            "Iteration 900: Cost = -0.2688723338622097\n",
            "Updated Weights: w1 = 0.3609968679567802, w2 = 0.8898013393865266, b = 0.34323933383082317\n",
            "---------------------------------------------------\n",
            "Iteration 910: Cost = -0.2681630901887875\n",
            "Updated Weights: w1 = 0.364135243362412, w2 = 0.8897852819100601, b = 0.341612084520075\n",
            "---------------------------------------------------\n",
            "Iteration 920: Cost = -0.2674724733627443\n",
            "Updated Weights: w1 = 0.3672187846731813, w2 = 0.889787812935311, b = 0.339982469494813\n",
            "---------------------------------------------------\n",
            "Iteration 930: Cost = -0.26679977532238486\n",
            "Updated Weights: w1 = 0.3702484998254417, w2 = 0.8898087415711078, b = 0.3383506720304297\n",
            "---------------------------------------------------\n",
            "Iteration 940: Cost = -0.2661443132105268\n",
            "Updated Weights: w1 = 0.3732253871116462, w2 = 0.8898478658288624, b = 0.33671687228136477\n",
            "---------------------------------------------------\n",
            "Iteration 950: Cost = -0.2655054287354279\n",
            "Updated Weights: w1 = 0.376150434788264, w2 = 0.8899049734928438, b = 0.33508124714329796\n",
            "---------------------------------------------------\n",
            "Iteration 960: Cost = -0.26488248752886473\n",
            "Updated Weights: w1 = 0.37902462071238896, w2 = 0.889979842957697, b = 0.333443970132926\n",
            "---------------------------------------------------\n",
            "Iteration 970: Cost = -0.2642748785030219\n",
            "Updated Weights: w1 = 0.38184891200618853, w2 = 0.8900722440333174, b = 0.33180521128442714\n",
            "---------------------------------------------------\n",
            "Iteration 980: Cost = -0.26368201320773843\n",
            "Updated Weights: w1 = 0.3846242647483457, w2 = 0.8901819387172822, b = 0.3301651370617098\n",
            "---------------------------------------------------\n",
            "Iteration 990: Cost = -0.2631033251895522\n",
            "Updated Weights: w1 = 0.38735162369164355, w2 = 0.8903086819351358, b = 0.32852391028554023\n",
            "---------------------------------------------------\n",
            "Accuracy: 89.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ZPwdLOkZTYH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}